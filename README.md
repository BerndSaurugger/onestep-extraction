# onestep-extraction
In this work, we have "extracted" training images from several diffusion models, similar to [1]. These are generated images which are exact copies of training set ones. Our attack is more efficient than [1], and our labeling can extract images which are not exactly the same, but vary in fixed spatial locations (see below). Read it on arxiv soon.

# Features

- [x] Verify our ground truth
- [ ] Perform our whitebox and blackbox attack vs. SDV1, SDV2, DeepIF, etc.
- [ ] Retrieve and create templates

[1] Extracting training data from diffusion models. arXiv preprint arXiv:2301.13188, 2023.

